{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-15T17:37:13.426439157Z",
     "start_time": "2023-12-15T17:37:12.254232786Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch as th\n",
    "\n",
    "from Datasets.TinyShakespeare.prepare import prepare_to_tokenize\n",
    "from Embeddings.token_embeddings import encode,decode\n",
    "from TransformerModel.transformer import TransformerDecoder, TransformerTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def nearest_lower_divisible(number, divisor):\n",
    "    return number - (number % divisor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T17:37:15.703541328Z",
     "start_time": "2023-12-15T17:37:15.684739188Z"
    }
   },
   "id": "8bbdbf5f2ddf801a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def param_search(trial_epochs: int, num_trials: int):\n",
    "    text = prepare_to_tokenize(\"/home/skyr/PycharmProjects/TransformerFromScratch/Datasets/TinyShakespeare/input.txt\")\n",
    "    with open(\"/home/skyr/PycharmProjects/TransformerFromScratch/Datasets/TinyShakespeare/vocab.json\", \"r\") as file:\n",
    "        vocab = json.load(file)\n",
    "\n",
    "    text = encode(text, vocab)\n",
    "\n",
    "    def objective(trial):\n",
    "        num_heads = trial.suggest_int(\"num_heads\", 4, 12)\n",
    "        base_embed = nearest_lower_divisible(min(num_heads ** 2, 90), num_heads)\n",
    "        factor = trial.suggest_int(\"factor\", 1, 6)\n",
    "        embedd_dim = base_embed * factor\n",
    "        dropout_p = trial.suggest_float(\"dropout_p\", 0.1, 0.55)\n",
    "        feed_forward_size = trial.suggest_int(\"feed_forward_size\", 600, 1800)\n",
    "        num_layers = trial.suggest_int(\"num_layers\", 4, 12)\n",
    "        block_size = trial.suggest_int(\"block_size\", 64, 128)\n",
    "        lr = trial.suggest_float(\"lr\", 1e-6, 7e-3)\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-1)\n",
    "        batch_size = 32\n",
    "        # transformer = TransformerDecoder(embedd_dim, num_heads, dropout_p, feed_forward_size, num_layers, len(vocab),\n",
    "        #                                  block_size)\n",
    "        # trainer = TransformerTrainer(transformer, th.optim.AdamW, th.nn.CrossEntropyLoss, lr, block_size, weight_decay)\n",
    "        data = list(chain.from_iterable(text))\n",
    "        test = data[:int(len(data) * 0.1)]\n",
    "        # val = data[int(len(data) * 0.1):int(len(data) * 0.2)]\n",
    "        train = data[int(len(data) * 0.2):]\n",
    "        train = th.tensor(train).long()\n",
    "        test = th.tensor(test).long()\n",
    "        # batch_size = find_batch_size(batch_size, trainer, train, test)\n",
    "        # del transformer\n",
    "        # del trainer\n",
    "        transformer = TransformerDecoder(embedd_dim, num_heads, dropout_p, feed_forward_size, num_layers, len(vocab),\n",
    "                                         block_size)\n",
    "        trainer = TransformerTrainer(transformer, th.optim.AdamW, th.nn.CrossEntropyLoss, lr, block_size, weight_decay,\n",
    "                                     vocab, None, log=False)\n",
    "        trainer.train(train, test, trial_epochs, batch_size)\n",
    "        return np.mean(trainer.test_losses).item()\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=num_trials)\n",
    "    # print(f\"Best params: {study.best_params}\")\n",
    "    fig = optuna.visualization.plot_optimization_history(study)\n",
    "    fig2 = optuna.visualization.plot_param_importances(study)\n",
    "    fig3 = optuna.visualization.plot_contour(study)\n",
    "    fig4 = optuna.visualization.plot_terminator_improvement(study)\n",
    "    fig.show()\n",
    "    fig2.show()\n",
    "    fig3.show()\n",
    "    fig4.show()\n",
    "    print(f\"Best value: {study.best_value}\")\n",
    "    with open(\"params.json\", \"w\") as file:\n",
    "        json.dump(study.best_params, file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1388c444f68edb59"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_search(1501, 100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e27ca0b37ad7e526"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
