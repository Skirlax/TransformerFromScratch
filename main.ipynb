{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "from Datasets.TinyShakespeare.prepare import prepare_to_tokenize\n",
    "from Embeddings.token_embeddings import encode,decode\n",
    "from TransformerModel.transformer import TransformerDecoder, TransformerTrainer\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:44:04.400869009Z",
     "start_time": "2023-12-01T18:44:03.825195078Z"
    }
   },
   "id": "41d81cbd34802a30"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:20:03.524667527Z",
     "start_time": "2023-12-01T18:20:03.492704380Z"
    }
   },
   "id": "f4f4bd3ca0bf4c1a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "vocab = json.load(open(\"vocab2.json\", \"r\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:44:18.177046158Z",
     "start_time": "2023-12-01T18:44:18.170383965Z"
    }
   },
   "id": "809f9d32e5db12c1"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def shift_vocab(vocab_: dict):\n",
    "    return {k:v - 1 for k,v in vocab.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:20:28.280282199Z",
     "start_time": "2023-12-01T18:20:28.266774866Z"
    }
   },
   "id": "99d8f3ad2cbc28c5"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# vocab = shift_vocab(vocab)\n",
    "with open(\"vocab2.json\",\"w\") as f:\n",
    "    json.dump(vocab,f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:21:15.367705863Z",
     "start_time": "2023-12-01T18:21:15.317593562Z"
    }
   },
   "id": "33dc779922b1757b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data = prepare_to_tokenize()\n",
    "\n",
    "data = encode(data, vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:44:23.550878664Z",
     "start_time": "2023-12-01T18:44:21.830200562Z"
    }
   },
   "id": "3d03ff2ff4d4ee9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "decoded_test = decode([data[1]],vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:44:24.399065528Z",
     "start_time": "2023-12-01T18:44:24.394971242Z"
    }
   },
   "id": "92a8c2803252b9d6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['before we proceed any further hear me speak']\n"
     ]
    }
   ],
   "source": [
    "print(decoded_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:44:24.730556627Z",
     "start_time": "2023-12-01T18:44:24.729166033Z"
    }
   },
   "id": "de4c07ab0df4c7c4"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:44:26.586473594Z",
     "start_time": "2023-12-01T18:44:26.580900922Z"
    }
   },
   "id": "d5978065c37a8dd5"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "embedd_dim = 300\n",
    "num_heads = 6\n",
    "dropout_p = 0.1\n",
    "output_size = 300\n",
    "num_layers = 6\n",
    "vocab_size = len(vocab)\n",
    "test_lr = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:44:27.700612945Z",
     "start_time": "2023-12-01T18:44:27.696836722Z"
    }
   },
   "id": "af58afb9622a874f"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "transformer = TransformerDecoder(embedd_dim,num_heads,dropout_p, output_size, num_layers, vocab_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:44:28.847027605Z",
     "start_time": "2023-12-01T18:44:28.818335679Z"
    }
   },
   "id": "ad64d8e4c6891bb2"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "trainer = TransformerTrainer(transformer,th.optim.Adam,th.nn.CrossEntropyLoss,test_lr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:44:29.352607567Z",
     "start_time": "2023-12-01T18:44:29.249653157Z"
    }
   },
   "id": "6950089b950c224e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "ts_data = th.tensor(np.array(data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:44:29.783952110Z",
     "start_time": "2023-12-01T18:44:29.781941277Z"
    }
   },
   "id": "883d9bccc9ef3886"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32777, 40])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:44:30.774818366Z",
     "start_time": "2023-12-01T18:44:30.769195589Z"
    }
   },
   "id": "7ce8a9e23d81133e"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "print(th.any(ts_data > 502))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:44:33.591141082Z",
     "start_time": "2023-12-01T18:44:33.581423235Z"
    }
   },
   "id": "7c43fe06de90680"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transformer training:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([503, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transformer training:   0%|          | 0/10 [00:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1024x300 and 50x300)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# pydev_debug_cell\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain(ts_data,\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m128\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/TransformerFromScratch/TransformerModel/transformer.py:72\u001B[0m, in \u001B[0;36mTransformerTrainer.train\u001B[0;34m(self, data, epochs, batch_size)\u001B[0m\n\u001B[1;32m     70\u001B[0m x_batch, y_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_batch(data,batch_size, \u001B[38;5;241m8\u001B[39m)\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 72\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer\u001B[38;5;241m.\u001B[39mforward(x_batch, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     73\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss(output, y_batch)\n\u001B[1;32m     74\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/PycharmProjects/TransformerFromScratch/TransformerModel/transformer.py:53\u001B[0m, in \u001B[0;36mTransformerDecoder.forward\u001B[0;34m(self, x, y)\u001B[0m\n\u001B[1;32m     51\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpositional_embedding\u001B[38;5;241m.\u001B[39mforward(x)\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dec_layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder_layers:\n\u001B[0;32m---> 53\u001B[0m     x \u001B[38;5;241m=\u001B[39m dec_layer\u001B[38;5;241m.\u001B[39mforward(x, y)\n\u001B[1;32m     54\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_norm\u001B[38;5;241m.\u001B[39mforward(x)\n\u001B[1;32m     55\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin\u001B[38;5;241m.\u001B[39mforward(x)\n",
      "File \u001B[0;32m~/PycharmProjects/TransformerFromScratch/TransformerModel/Layers/decoder_layer.py:19\u001B[0m, in \u001B[0;36mDecoderLayer.forward\u001B[0;34m(self, x, encoder_output)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, encoder_output):\n\u001B[0;32m---> 19\u001B[0m     self_masked_attn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mself_masked_attn\u001B[38;5;241m.\u001B[39mforward(x, mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     20\u001B[0m     x \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(self_masked_attn_output)\n\u001B[1;32m     21\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_norm1\u001B[38;5;241m.\u001B[39mforward(x)\n",
      "File \u001B[0;32m~/PycharmProjects/TransformerFromScratch/TransformerModel/Blocks/mutli_head_attention.py:50\u001B[0m, in \u001B[0;36mMultiHeadAttention.forward\u001B[0;34m(self, x, mask, encoder_output)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, mask: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m, encoder_output: \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m th\u001B[38;5;241m.\u001B[39mtensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m th\u001B[38;5;241m.\u001B[39mtensor:\n\u001B[0;32m---> 50\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmasked_attention(x, mask, encoder_output\u001B[38;5;241m=\u001B[39mencoder_output)\n\u001B[1;32m     51\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m th\u001B[38;5;241m.\u001B[39mcat([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin(outputs[i]) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads)], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/PycharmProjects/TransformerFromScratch/TransformerModel/Blocks/mutli_head_attention.py:26\u001B[0m, in \u001B[0;36mMultiHeadAttention.masked_attention\u001B[0;34m(self, x, mask, encoder_output)\u001B[0m\n\u001B[1;32m     24\u001B[0m     mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_mask(x)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (q, k, v) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mQs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mKs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mVs)):\n\u001B[0;32m---> 26\u001B[0m     Q \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m@\u001B[39m q\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m encoder_output \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     28\u001B[0m         K \u001B[38;5;241m=\u001B[39m k(encoder_output)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (1024x300 and 50x300)"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.train(ts_data,10,128)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T18:44:53.337537005Z",
     "start_time": "2023-12-01T18:44:36.079107775Z"
    }
   },
   "id": "7601c80c495ce78c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
